{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Célula 1 – Montar Drive e verificar GPU"
      ],
      "metadata": {
        "id": "jEAlDuEXB9E8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import torch\n",
        "print('CUDA disponível:', torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print('Device:', torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "r3qs30S8AuHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Célula 2 – Clonar repositório e instalar pacote"
      ],
      "metadata": {
        "id": "cTfjAKKhA8p8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/opontorno/DeepFeatureX-SN.git\n",
        "%cd /content/DeepFeatureX-SN\n",
        "!pip install -e ."
      ],
      "metadata": {
        "id": "Yh6ey1K8A-XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Célula 3 – Extrair weights (.tar.gz)"
      ],
      "metadata": {
        "id": "NRJgrkI8BfIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "\n",
        "# Caminho do .tar.gz no Drive\n",
        "TAR_PATH = '/content/drive/MyDrive/tcc/dfx/weights.tar.gz'\n",
        "\n",
        "# Pasta onde extrair (será o working_dir; deve conter \"models\" ao final)\n",
        "WORKING_DIR = '/content/drive/MyDrive/tcc/dfx'\n",
        "os.makedirs(WORKING_DIR, exist_ok=True)\n",
        "\n",
        "with tarfile.open(TAR_PATH, 'r:gz') as tf:\n",
        "    tf.extractall(WORKING_DIR)\n",
        "\n",
        "# Conferir\n",
        "!ls \"{WORKING_DIR}\"\n",
        "!ls \"{WORKING_DIR}/models/siamese-approach\"\n",
        "print('Working dir:', WORKING_DIR)"
      ],
      "metadata": {
        "id": "uU6sWAb9Bhrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Célula 4 – Criar wd.py"
      ],
      "metadata": {
        "id": "eEbUZCiIBna6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "REPO_ROOT = '/content/DeepFeatureX-SN'\n",
        "# Pasta que contém a pasta \"models\" (não use .../dfx/weights)\n",
        "WORKING_DIR = '/content/drive/MyDrive/tcc/dfx'\n",
        "\n",
        "wd_content = f'''import os\n",
        "working_dir = {repr(WORKING_DIR)}\n",
        "'''\n",
        "with open(os.path.join(REPO_ROOT, 'src', 'dfx', 'wd.py'), 'w') as f:\n",
        "    f.write(wd_content)\n",
        "\n",
        "print('wd.py criado. working_dir =', WORKING_DIR)"
      ],
      "metadata": {
        "id": "KJ9krv4-BpAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Célula 5 – Carregar modelo"
      ],
      "metadata": {
        "id": "T6rgshCAB4Bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "REPO_ROOT = '/content/DeepFeatureX-SN'\n",
        "sys.path.insert(0, os.path.join(REPO_ROOT, 'src'))\n",
        "\n",
        "import torch\n",
        "from dfx import get_complete_model, get_trans, get_path\n",
        "\n",
        "# Backbone disponível nos seus weights: densenet121 ou densenet161\n",
        "BACKBONE = 'densenet121'\n",
        "models_dir = get_path('models')\n",
        "\n",
        "model = get_complete_model(BACKBONE, models_dir=models_dir)\n",
        "weight_path = f'{models_dir}/complete/{BACKBONE}.pt'\n",
        "model.load_state_dict(torch.load(weight_path, map_location='cpu'))\n",
        "model.eval()\n",
        "\n",
        "trans = get_trans(model_name=BACKBONE)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "print('Modelo carregado. Backbone:', BACKBONE, '| Device:', device)"
      ],
      "metadata": {
        "id": "sjg2kjrlB5Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Célula 7 – Inferência (upload no Colab)"
      ],
      "metadata": {
        "id": "kMN1VbxyCAk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "\n",
        "datasets_path = '/content/drive/MyDrive/tcc/dfx/teste_inferencia'\n",
        "import torch\n",
        "from dfx import dataset_for_robustness, get_trans, make_balanced\n",
        "\n",
        "trans = get_trans(model_name='densenet121')\n",
        "dataset = dataset_for_robustness(dset_dir=datasets_path, transforms=trans)\n",
        "\n",
        "GROUP_SIZE = 12\n",
        "LABELS = ['DM', 'GAN', 'Real']\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "def tensor_to_img(t):\n",
        "    x = t.cpu().numpy().transpose(1, 2, 0)\n",
        "    x = x * std + mean\n",
        "    x = np.clip(x, 0, 1)\n",
        "    return x\n",
        "\n",
        "n_total = len(dataset)\n",
        "if n_total == 0:\n",
        "    print('Dataset vazio. Verifique o caminho:', datasets_path)\n",
        "else:\n",
        "    model.eval()\n",
        "    num_groups = (n_total + GROUP_SIZE - 1) // GROUP_SIZE\n",
        "\n",
        "    for g in range(num_groups):\n",
        "        start = g * GROUP_SIZE\n",
        "        end = min(start + GROUP_SIZE, n_total)\n",
        "        n_show = end - start\n",
        "\n",
        "        cols = 4\n",
        "        rows = max(1, (n_show + cols - 1) // cols)\n",
        "        fig, axes = plt.subplots(rows, cols, figsize=(3 * cols, 3 * rows))\n",
        "        if n_show == 1:\n",
        "            axes = np.array([axes])\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for i in range(n_show):\n",
        "            idx = start + i\n",
        "            img_tensor, true_class, _ = dataset[idx]\n",
        "            true_class = int(true_class.item())\n",
        "            # retrieves the name of the model that generated the img\n",
        "            arch_name = Path(dataset.files[idx]['file']).parent.name\n",
        "\n",
        "            x = img_tensor.unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                logits = model(x)\n",
        "                pred = logits.argmax(dim=1).item()\n",
        "            img_display = tensor_to_img(img_tensor)\n",
        "            axes[i].imshow(img_display)\n",
        "            axes[i].axis('off')\n",
        "            color = 'green' if pred == true_class else 'red'\n",
        "            axes[i].set_title(f'Esperado: {LABELS[true_class]} ({arch_name}) | Pred: {LABELS[pred]}', fontsize=10, color=color)\n",
        "\n",
        "        for j in range(n_show, len(axes)):\n",
        "            axes[j].axis('off')\n",
        "\n",
        "        plt.suptitle(f'Grupo {g+1}/{num_groups} — imagens {start+1}–{end} de {n_total}', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "t09Bf7UN3QmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### testando no proprio dataset do autor :"
      ],
      "metadata": {
        "id": "mkPT71hMAk30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "\n",
        "datasets_path = '/content/drive/MyDrive/tcc/dfx/datasets'\n",
        "import torch\n",
        "from dfx import dataset_for_robustness, get_trans, make_balanced\n",
        "\n",
        "trans = get_trans(model_name='densenet121')\n",
        "dataset = dataset_for_robustness(dset_dir=datasets_path, transforms=trans)\n",
        "\n",
        "GROUP_SIZE = 12\n",
        "LABELS = ['DM', 'GAN', 'Real']\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "def tensor_to_img(t):\n",
        "    x = t.cpu().numpy().transpose(1, 2, 0)\n",
        "    x = x * std + mean\n",
        "    x = np.clip(x, 0, 1)\n",
        "    return x\n",
        "\n",
        "n_total = len(dataset)\n",
        "if n_total == 0:\n",
        "    print('Dataset vazio. Verifique o caminho:', datasets_path)\n",
        "else:\n",
        "    model.eval()\n",
        "    num_groups = (n_total + GROUP_SIZE - 1) // GROUP_SIZE\n",
        "\n",
        "    for g in range(num_groups):\n",
        "        start = g * GROUP_SIZE\n",
        "        end = min(start + GROUP_SIZE, n_total)\n",
        "        n_show = end - start\n",
        "\n",
        "        cols = 4\n",
        "        rows = max(1, (n_show + cols - 1) // cols)\n",
        "        fig, axes = plt.subplots(rows, cols, figsize=(3 * cols, 3 * rows))\n",
        "        if n_show == 1:\n",
        "            axes = np.array([axes])\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for i in range(n_show):\n",
        "            idx = start + i\n",
        "            img_tensor, true_class, _ = dataset[idx]\n",
        "            true_class = int(true_class.item())\n",
        "            # retrieves the name of the model that generated the img\n",
        "            arch_name = Path(dataset.files[idx]['file']).parent.name\n",
        "\n",
        "            x = img_tensor.unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                logits = model(x)\n",
        "                pred = logits.argmax(dim=1).item()\n",
        "            img_display = tensor_to_img(img_tensor)\n",
        "            axes[i].imshow(img_display)\n",
        "            axes[i].axis('off')\n",
        "            color = 'green' if pred == true_class else 'red'\n",
        "            axes[i].set_title(f'Esperado: {LABELS[true_class]} ({arch_name}) | Pred: {LABELS[pred]}', fontsize=10, color=color)\n",
        "\n",
        "        for j in range(n_show, len(axes)):\n",
        "            axes[j].axis('off')\n",
        "\n",
        "        plt.suptitle(f'Grupo {g+1}/{num_groups} — imagens {start+1}–{end} de {n_total}', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "mwU2t_LZAkds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OBlLUDnzYSEU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}